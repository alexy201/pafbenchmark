from typing import Dict, Any, Optional, Tuple
from warnings import warn

import numpy as np
import pytorch_lightning as pl
import torch
import torch.distributed as dist
from omegaconf import DictConfig
from pytorch_lightning.utilities.types import STEP_OUTPUT
from spikingjelly.activation_based import functional  # ðŸ¤—ðŸ¤—

from data.genx_utils.labels import ObjectLabels
from data.utils.types import DataType, DatasetSamplingMode, ObjDetOutput
from models.detection.yolox.utils import postprocess
from models.detection.yolox_extension.models.detector import YoloXDetector
from models.spikingVit import SpikingVit
from modules.utils.detection import Mode, SNNStates, merge_mixed_batches, BackboneFeatureSelector, EventReprSelector, \
    mode_2_string
from utils.evaluation.prophesee.evaluator import PropheseeEvaluator
from utils.evaluation.prophesee.io.box_loading import to_prophesee
from utils.padding import InputPadderFromShape


class Module(pl.LightningModule):
    def __init__(self, full_config):
        super().__init__()
        self.mode_2_psee_evaluator = None
        self.mode_2_sampling_mode = None
        self.mode_2_batch_size = None
        self.mode_2_hw = None
        assert isinstance(full_config, DictConfig)
        self.train_metrics_config = None
        self.train_config = None
        self.started_training = None
        self.full_config = full_config

        self.mdl_config = full_config.model
        self.mdl = YoloXDetector(self.mdl_config)

        self.encoder_model = full_config.encoder_model
        self.training_config = self.full_config.training

        in_res_hw = tuple(self.encoder_model.encoder.in_res_hw)
        self.input_padder = InputPadderFromShape(desired_hw=in_res_hw)

        self.model = SpikingVit(full_config)

        self.mode_2_snn_states: Dict[Mode, SNNStates] = {
            Mode.TRAIN: SNNStates(),
            Mode.VAL: SNNStates(),
            Mode.TEST: SNNStates(),
        }

        self.example_input_array = None

    def setup(self, stage: Optional[str] = None) -> None:
        dataset_name = self.full_config.dataset.name
        self.mode_2_hw: Dict[Mode, Optional[Tuple[int, int]]] = {}
        self.mode_2_batch_size: Dict[Mode, Optional[int]] = {}
        self.mode_2_psee_evaluator: Dict[Mode, Optional[PropheseeEvaluator]] = {}
        self.mode_2_sampling_mode: Dict[Mode, DatasetSamplingMode] = {}

        self.started_training = True

        dataset_train_sampling = self.full_config.dataset.train.sampling
        dataset_eval_sampling = self.full_config.dataset.eval.sampling
        assert dataset_train_sampling in iter(DatasetSamplingMode)
        assert dataset_eval_sampling in (DatasetSamplingMode.STREAM, DatasetSamplingMode.RANDOM)
        if stage == 'fit':
            self.train_config = self.full_config.training
            self.train_metrics_config = self.full_config.logging.train.metrics

            if self.train_metrics_config.compute:
                self.mode_2_psee_evaluator[Mode.TRAIN] = PropheseeEvaluator(
                    dataset=dataset_name, downsample_by_2=self.full_config.dataset.downsample_by_factor_2)
            self.mode_2_psee_evaluator[Mode.VAL] = PropheseeEvaluator(
                dataset=dataset_name, downsample_by_2=self.full_config.dataset.downsample_by_factor_2)
            self.mode_2_sampling_mode[Mode.TRAIN] = dataset_train_sampling
            self.mode_2_sampling_mode[Mode.VAL] = dataset_eval_sampling

            for mode in (Mode.TRAIN, Mode.VAL):
                self.mode_2_hw[mode] = None
                self.mode_2_batch_size[mode] = None
            self.started_training = False
        elif stage == 'validate':
            mode = Mode.VAL
            self.mode_2_psee_evaluator[mode] = PropheseeEvaluator(
                dataset=dataset_name, downsample_by_2=self.full_config.dataset.downsample_by_factor_2)
            self.mode_2_sampling_mode[Mode.VAL] = dataset_eval_sampling
            self.mode_2_hw[mode] = None
            self.mode_2_batch_size[mode] = None
        elif stage == 'test':
            mode = Mode.TEST
            self.mode_2_psee_evaluator[mode] = PropheseeEvaluator(
                dataset=dataset_name, downsample_by_2=self.full_config.dataset.downsample_by_factor_2)
            self.mode_2_sampling_mode[Mode.TEST] = dataset_eval_sampling
            self.mode_2_hw[mode] = None
            self.mode_2_batch_size[mode] = None
        else:
            raise NotImplementedError

    @staticmethod
    def get_worker_id_from_batch(batch: Any) -> int:
        return batch['worker_id']

    @staticmethod
    def get_data_from_batch(batch: Any):
        return batch['data']

    def training_step(self, batch: Any, batch_idx: int) -> STEP_OUTPUT:
        batch = merge_mixed_batches(batch)
        data = self.get_data_from_batch(batch)
        worker_id = self.get_worker_id_from_batch(batch)

        mode = Mode.TRAIN
        self.started_training = True
        step = self.trainer.global_step

        ev_tensor_sequence = data[DataType.EV_REPR]
        sparse_obj_labels = data[DataType.OBJLABELS_SEQ]
        is_first_sample = data[DataType.IS_FIRST_SAMPLE]

        self.mode_2_snn_states[mode].reset(worker_id=worker_id, indices_or_bool_tensor=is_first_sample)
        sequence_len = len(ev_tensor_sequence)

        assert sequence_len > 0
        batch_size = len(sparse_obj_labels[0])

        if self.mode_2_batch_size[mode] is None:
            self.mode_2_batch_size[mode] = batch_size
        else:
            assert self.mode_2_batch_size[mode] == batch_size

        prev_states = self.mode_2_snn_states[mode].get_states(worker_id=worker_id)
        encoder_feature_selector = BackboneFeatureSelector()
        ev_repr_selector = EventReprSelector()
        obj_labels = list()
        for t_idx in range(sequence_len):
            ev_tensors = ev_tensor_sequence[t_idx]
            ev_tensors = ev_tensors.to(dtype=self.dtype)
            ev_tensors = self.input_padder.pad_tensor_ev_repr(ev_tensors)

            if self.mode_2_hw[mode] is None:
                self.mode_2_hw[mode] = tuple(ev_tensors.shape[-2:])
            else:
                assert self.mode_2_hw[mode] == ev_tensors.shape[-2:]

            # ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤— forward encoder ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—
            encoder_features, states = self.model.forward_encoder(x=ev_tensors, previous_states=prev_states)

            prev_states = states

            current_labels, valid_batch_indices = sparse_obj_labels[t_idx].get_valid_labels_and_batch_indices()
            if len(current_labels) > 0:
                encoder_feature_selector.add_backbone_features(backbone_features=encoder_features,
                                                               selected_indices=valid_batch_indices)
                obj_labels.extend(current_labels)
                ev_repr_selector.add_event_representations(event_representations=ev_tensors,
                                                           selected_indices=valid_batch_indices)

        self.mode_2_snn_states[mode].save_states_and_detach(worker_id=worker_id, states=prev_states)
        assert len(obj_labels) > 0

        selected_encoder_features = encoder_feature_selector.get_batched_backbone_features()
        labels = ObjectLabels.get_labels_as_batched_tensor(obj_label_list=obj_labels, format_='yolox')

        # ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤— forward decoder ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—
        predictions, losses = self.mdl.forward_detect(backbone_features=selected_encoder_features,
                                                      targets=labels)

        # ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤— reset spike ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—
        functional.reset_net(self.model)

        if self.mode_2_sampling_mode[mode] in (DatasetSamplingMode.MIXED, DatasetSamplingMode.RANDOM):
            # We only want to evaluate the last batch_size samples if we use random sampling (or mixed).
            # This is because otherwise we would mostly evaluate the init phase of the sequence.
            predictions = predictions[-batch_size:]
            obj_labels = obj_labels[-batch_size:]

        pred_processed = postprocess(prediction=predictions,
                                     num_classes=self.mdl_config.head.num_classes,
                                     conf_thre=self.mdl_config.postprocess.confidence_threshold,
                                     nms_thre=self.mdl_config.postprocess.nms_threshold)

        loaded_labels_proph, yolox_preds_proph = to_prophesee(obj_labels, pred_processed)
        assert losses is not None
        assert 'loss' in losses

        output = {
            ObjDetOutput.LABELS_PROPH: loaded_labels_proph[-batch_size:],
            ObjDetOutput.PRED_PROPH: yolox_preds_proph[-batch_size:],
            ObjDetOutput.EV_REPR: ev_repr_selector.get_event_representations_as_list(start_idx=-batch_size),

            ObjDetOutput.SKIP_VIZ: False,
            'loss': losses['loss']
        }

        # Logging
        prefix = f'{mode_2_string[mode]}/'
        log_dict = {f'{prefix}{k}': v for k, v in losses.items()}
        self.log_dict(log_dict, on_step=True, on_epoch=True, batch_size=batch_size, sync_dist=True)  # log loss dict

        if mode in self.mode_2_psee_evaluator:
            self.mode_2_psee_evaluator[mode].add_labels(loaded_labels_proph)
            self.mode_2_psee_evaluator[mode].add_predictions(yolox_preds_proph)
            if self.train_metrics_config.detection_metrics_every_n_steps is not None and \
                    step > 0 and step % self.train_metrics_config.detection_metrics_every_n_steps == 0:
                self.run_psee_evaluator(mode=mode)

        return output

    def _val_and_test_impl(self, batch: Any, mode: Mode) -> Optional[STEP_OUTPUT] | Any:
        data = self.get_data_from_batch(batch)
        assert mode in (Mode.VAL, Mode.TEST)
        ev_tensor_sequence = data[DataType.EV_REPR]
        sparse_obj_labels = data[DataType.OBJLABELS_SEQ]
        sequence_len = len(ev_tensor_sequence)
        assert sequence_len > 0
        batch_size = len(sparse_obj_labels)
        if self.mode_2_batch_size[mode] is None:
            self.mode_2_batch_size[mode] = batch_size
        else:
            assert self.mode_2_batch_size[mode] == batch_size

        encoder_feature_selector = BackboneFeatureSelector()
        ev_repr_selector = EventReprSelector()
        obj_labels = list()
        prev_states = None
        for t_idx in range(sequence_len):
            collect_predictions = (t_idx == sequence_len - 1) or \
                                  (self.mode_2_sampling_mode[mode] == DatasetSamplingMode.STREAM)
            ev_tensors = ev_tensor_sequence[t_idx]
            ev_tensors = ev_tensors.to(dtype=self.dtype)
            ev_tensors = self.input_padder.pad_tensor_ev_repr(ev_tensors)
            if self.mode_2_hw[mode] is None:
                self.mode_2_hw[mode] = tuple(ev_tensors.shape[-2:])
            else:
                assert self.mode_2_hw[mode] == ev_tensors.shape[-2:]

            # ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤— forward encoder ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—
            encoder_features, states = self.model.forward_encoder(x=ev_tensors, previous_states=prev_states)

            prev_states = states

            if collect_predictions:
                current_labels, valid_batch_indices = sparse_obj_labels[t_idx].get_valid_labels_and_batch_indices()
                # Store backbone features that correspond to the available labels.
                if len(current_labels) > 0:
                    encoder_feature_selector.add_backbone_features(backbone_features=encoder_features,
                                                                   selected_indices=valid_batch_indices)
                    obj_labels.extend(current_labels)
                    ev_repr_selector.add_event_representations(event_representations=ev_tensors,
                                                               selected_indices=valid_batch_indices)

        if len(obj_labels) == 0:
            return {ObjDetOutput.SKIP_VIZ: True}

        selected_encoder_features = encoder_feature_selector.get_batched_backbone_features()

        # ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤— reset spike ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—
        functional.reset_net(self.model)

        predictions, _ = self.mdl.forward_detect(backbone_features=selected_encoder_features)

        pred_processed = postprocess(prediction=predictions,
                                     num_classes=self.mdl_config.head.num_classes,
                                     conf_thre=self.mdl_config.postprocess.confidence_threshold,
                                     nms_thre=self.mdl_config.postprocess.nms_threshold)

        loaded_labels_proph, yolox_preds_proph = to_prophesee(obj_labels, pred_processed)

        output = {
            ObjDetOutput.LABELS_PROPH: loaded_labels_proph[-1],
            ObjDetOutput.PRED_PROPH: yolox_preds_proph[-1],
            ObjDetOutput.EV_REPR: ev_repr_selector.get_event_representations_as_list(start_idx=-1)[0],
            ObjDetOutput.SKIP_VIZ: False,
        }

        if self.started_training:
            self.mode_2_psee_evaluator[mode].add_labels(loaded_labels_proph)
            self.mode_2_psee_evaluator[mode].add_predictions(yolox_preds_proph)

        return output

    def validation_step(self, batch: Any, batch_idx: int) -> Optional[STEP_OUTPUT]:
        return self._val_and_test_impl(batch=batch, mode=Mode.VAL)

    def test_step(self, batch: Any, batch_idx: int) -> Optional[STEP_OUTPUT]:
        return self._val_and_test_impl(batch=batch, mode=Mode.TEST)

    def run_psee_evaluator(self, mode: Mode):
        psee_evaluator = self.mode_2_psee_evaluator[mode]
        batch_size = self.mode_2_batch_size[mode]
        hw_tuple = self.mode_2_hw[mode]
        if psee_evaluator is None:
            warn(f'psee_evaluator is None in {mode=}', UserWarning, stacklevel=2)
            return
        assert batch_size is not None
        assert hw_tuple is not None
        if psee_evaluator.has_data():
            # ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤— calculate metrics ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—ðŸ¤—
            metrics = psee_evaluator.evaluate_buffer(img_height=hw_tuple[0],
                                                     img_width=hw_tuple[1])
            assert metrics is not None
            prefix = f'{mode_2_string[mode]}/'

            step = self.trainer.global_step
            log_dict = {}
            for k, v in metrics.items():
                if isinstance(v, (int, float)):
                    value = torch.tensor(v)
                elif isinstance(v, np.ndarray):
                    value = torch.from_numpy(v)
                elif isinstance(v, torch.Tensor):
                    value = v
                else:
                    raise NotImplementedError
                assert value.ndim == 0, f'tensor must be a scalar.\n{v=}\n{type(v)=}\n{value=}\n{type(value)=}'
                # put them on the current device to avoid this error: https://github.com/Lightning-AI/lightning/discussions/2529
                log_dict[f'{prefix}{k}'] = value.to(self.device)
            # Somehow self.log does not work when we eval during the training epoch.
            self.log_dict(log_dict, on_step=False, on_epoch=True, batch_size=batch_size, sync_dist=True)
            if dist.is_available() and dist.is_initialized():
                # We now have to manually sync (average the metrics) across processes in case of distributed training.
                # NOTE: This is necessary to ensure that we have the same numbers for the checkpoint metric (metadata)
                # and wandb metric:
                # - checkpoint callback is using the self.log function which uses global sync (avg across ranks)
                # - wandb uses log_metrics that we reduce manually to global rank 0
                dist.barrier()
                for k, v in log_dict.items():
                    dist.reduce(log_dict[k], dst=0, op=dist.ReduceOp.SUM)
                    if dist.get_rank() == 0:
                        log_dict[k] /= dist.get_world_size()
            if self.trainer.is_global_zero:
                # For some reason we need to increase the step by 2 to enable consistent logging in wandb here.
                # I might not understand wandb login correctly. This works reasonably well for now.
                add_hack = 2
                self.logger.log_metrics(metrics=log_dict, step=step + add_hack)

            psee_evaluator.reset_buffer()
        else:
            warn(f'psee_evaluator has not data in {mode=}', UserWarning, stacklevel=2)

    def on_train_epoch_end(self) -> None:
        mode = Mode.TRAIN
        if mode in self.mode_2_psee_evaluator and \
                self.train_metrics_config.detection_metrics_every_n_steps is None and \
                self.mode_2_hw[mode] is not None:
            # For some reason PL calls this function when resuming.
            # We don't know yet the value of train_height_width, so we skip this
            self.run_psee_evaluator(mode=mode)

    def on_validation_epoch_end(self) -> None:
        mode = Mode.VAL
        if self.started_training:
            assert self.mode_2_psee_evaluator[mode].has_data()
            self.run_psee_evaluator(mode=mode)

    def on_test_epoch_end(self) -> None:
        mode = Mode.TEST
        assert self.mode_2_psee_evaluator[mode].has_data()
        self.run_psee_evaluator(mode=mode)

    def configure_optimizers(self) -> Any:
        lr = self.training_config.learning_rate
        weight_decay = self.train_config.weight_decay
        optimizer = torch.optim.AdamW(self.parameters(), lr=lr, weight_decay=weight_decay)

        scheduler_params = self.training_config.lr_scheduler
        if not scheduler_params.use:
            return optimizer

        total_steps = scheduler_params.total_steps
        assert total_steps is not None
        assert total_steps > 0

        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer,
                                                                            T_0=300000)
        lr_scheduler_config = {
            "scheduler": lr_scheduler,
            "interval": "step",
            "frequency": 1,
            "strict": True,
            "name": 'learning_rate',
        }

        return {'optimizer': optimizer, 'lr_scheduler': lr_scheduler_config}
